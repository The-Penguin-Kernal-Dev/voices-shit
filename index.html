<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Voice Activated Avatar</title>
<style>
  body, html {
    margin: 0; padding: 0; height: 100%; 
    background: #111; 
    display: flex; 
    justify-content: center; 
    align-items: center;
    overflow: hidden;
  }
  .avatar-container {
    position: relative;
    width: 100vmin;
    height: 100vmin;
  }
  .avatar-image {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    object-fit: contain;
    opacity: 0;
    transition: opacity 0.3s ease-in-out;
  }
  .active {
    opacity: 1;
  }
  #error {
    display: none;
    position: fixed;
    top: 20px;
    color: white;
    background: #c00;
    padding: 15px;
    border-radius: 5px;
    max-width: 80%;
    text-align: center;
  }
</style>
</head>
<body>
  <div class="avatar-container">
    <img id="idleAvatar" class="avatar-image active" src="https://i.ibb.co/chqZCvGC/idle.png" alt="Idle Avatar" />
    <img id="talkingAvatar" class="avatar-image" src="https://i.ibb.co/Jw5PDXWp/talking.png" alt="Talking Avatar" />
  </div>
  <div id="error"></div>

<script>
const AVATAR_STATES = {
  IDLE: 'idle',
  TALKING: 'talking'
};

// Configuration
const AUDIO_CONFIG = {
  FFT_SIZE: 2048,
  SMOOTHING_FACTOR: 0.8,
  RMS_THRESHOLD: 0.02,
  SILENT_FRAMES_THRESHOLD: 8,
  MIN_VOICE_DURATION: 100 // ms
};

// State management
let currentState = AVATAR_STATES.IDLE;
let lastStateChange = 0;
let mediaStream = null;
let audioContext = null;
let analyser = null;

const idleAvatar = document.getElementById('idleAvatar');
const talkingAvatar = document.getElementById('talkingAvatar');
const errorDiv = document.getElementById('error');

// Preload images
new Image().src = idleAvatar.src;
new Image().src = talkingAvatar.src;

function setAvatarState(newState) {
  if (newState === currentState) return;
  
  const now = Date.now();
  if (now - lastStateChange < AUDIO_CONFIG.MIN_VOICE_DURATION) return;
  
  lastStateChange = now;
  currentState = newState;
  
  idleAvatar.classList.toggle('active', newState === AVATAR_STATES.IDLE);
  talkingAvatar.classList.toggle('active', newState === AVATAR_STATES.TALKING);
}

async function initializeAudio() {
  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    setupAudioAnalysis();
    window.addEventListener('beforeunload', cleanup);
  } catch (err) {
    showError('Microphone access required. Please allow access and refresh.');
    console.error('Audio initialization error:', err);
  }
}

function setupAudioAnalysis() {
  audioContext = new AudioContext();
  const source = audioContext.createMediaStreamSource(mediaStream);
  analyser = audioContext.createAnalyser();
  
  analyser.fftSize = AUDIO_CONFIG.FFT_SIZE;
  source.connect(analyser);
  
  const bufferLength = analyser.fftSize;
  const dataArray = new Uint8Array(bufferLength);
  let smoothing = 0;
  let silentFrames = 0;

  function analyzeAudio() {
    analyser.getByteTimeDomainData(dataArray);
    
    // Calculate RMS from time domain data
    let sumSquares = 0;
    for (let i = 0; i < bufferLength; i++) {
      const sample = (dataArray[i] - 128) / 128;
      sumSquares += sample * sample;
    }
    const rms = Math.sqrt(sumSquares / bufferLength);
    
    // Apply smoothing
    smoothing = smoothing * AUDIO_CONFIG.SMOOTHING_FACTOR + 
               rms * (1 - AUDIO_CONFIG.SMOOTHING_FACTOR);

    // State transition logic
    if (smoothing > AUDIO_CONFIG.RMS_THRESHOLD) {
      silentFrames = 0;
      setAvatarState(AVATAR_STATES.TALKING);
    } else {
      if (++silentFrames >= AUDIO_CONFIG.SILENT_FRAMES_THRESHOLD) {
        setAvatarState(AVATAR_STATES.IDLE);
      }
    }

    requestAnimationFrame(analyzeAudio);
  }

  analyzeAudio();
}

function showError(message) {
  errorDiv.textContent = message;
  errorDiv.style.display = 'block';
}

function cleanup() {
  if (mediaStream) {
    mediaStream.getTracks().forEach(track => track.stop());
  }
  if (audioContext) {
    audioContext.close();
  }
}

// Initialize on user interaction
window.addEventListener('click', async () => {
  if (!mediaStream) {
    await initializeAudio();
  }
  if (audioContext && audioContext.state === 'suspended') {
    await audioContext.resume();
  }
});

// Initial setup
initializeAudio();
</script>
</body>
</html>
